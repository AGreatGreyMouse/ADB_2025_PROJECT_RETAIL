{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5fe9423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T06:41:44.620923Z",
     "start_time": "2022-07-15T06:41:43.916810Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcf182",
   "metadata": {},
   "source": [
    "## Generate AGG_HYB_FCST table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a806a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T12:11:41.101095Z",
     "start_time": "2022-07-17T12:11:41.042784Z"
    }
   },
   "outputs": [],
   "source": [
    "AGG_HYB_FCST = pd.DataFrame(\n",
    "    {\n",
    "        'PRODUCT_LVL_ID6': [x for x in range(600001, 602001)],\n",
    "        'LOCATION_LVL_ID8': [x for x in range(800001, 802001)],\n",
    "        'CUSTOMER_LVL_ID6': [x for x in range(600001, 602001)],\n",
    "        'DISTR_CHANNEL_LVL_ID6': [x for x in range(600001, 602001)],\n",
    "        'PERIOD_DT': pd.date_range(start='2015-01-01', periods=2000, freq='MS'),\n",
    "        'PERIOD_END_DT': pd.date_range(start='2015-02-01', periods=2000, freq='MS'),\n",
    "        'SEGMENT_NAME': ['name1' for x in range(600001, 602001)],\n",
    "        'VF_FORECAST_VALUE': np.random.uniform(0, 100, 2000),\n",
    "        'DEMAND_TYPE': np.random.randint(0, 2, 2000),\n",
    "        'ASSORTMENT_TYPE': np.random.choice(['new', 'old'], 2000),\n",
    "        'ML_FORECAST_VALUE': np.random.uniform(0, 100, 2000),\n",
    "        'HYBRID_FORECAST_VALUE': np.random.uniform(0, 100, 2000)\n",
    "    }\n",
    "                           )\n",
    "\n",
    "AGG_HYB_FCST['PERIOD_DT'] += pd.Timedelta('1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a849d2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T12:11:41.590149Z",
     "start_time": "2022-07-17T12:11:41.574673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_LVL_ID6</th>\n",
       "      <th>LOCATION_LVL_ID8</th>\n",
       "      <th>CUSTOMER_LVL_ID6</th>\n",
       "      <th>DISTR_CHANNEL_LVL_ID6</th>\n",
       "      <th>PERIOD_DT</th>\n",
       "      <th>PERIOD_END_DT</th>\n",
       "      <th>SEGMENT_NAME</th>\n",
       "      <th>VF_FORECAST_VALUE</th>\n",
       "      <th>DEMAND_TYPE</th>\n",
       "      <th>ASSORTMENT_TYPE</th>\n",
       "      <th>ML_FORECAST_VALUE</th>\n",
       "      <th>HYBRID_FORECAST_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600001</td>\n",
       "      <td>800001</td>\n",
       "      <td>600001</td>\n",
       "      <td>600001</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>name1</td>\n",
       "      <td>9.190933</td>\n",
       "      <td>0</td>\n",
       "      <td>old</td>\n",
       "      <td>2.833737</td>\n",
       "      <td>27.708736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600002</td>\n",
       "      <td>800002</td>\n",
       "      <td>600002</td>\n",
       "      <td>600002</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>name1</td>\n",
       "      <td>74.199686</td>\n",
       "      <td>1</td>\n",
       "      <td>new</td>\n",
       "      <td>44.958590</td>\n",
       "      <td>45.786556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600003</td>\n",
       "      <td>800003</td>\n",
       "      <td>600003</td>\n",
       "      <td>600003</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>name1</td>\n",
       "      <td>90.215905</td>\n",
       "      <td>1</td>\n",
       "      <td>new</td>\n",
       "      <td>40.587812</td>\n",
       "      <td>67.570161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600004</td>\n",
       "      <td>800004</td>\n",
       "      <td>600004</td>\n",
       "      <td>600004</td>\n",
       "      <td>2015-04-02</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>name1</td>\n",
       "      <td>4.658254</td>\n",
       "      <td>0</td>\n",
       "      <td>old</td>\n",
       "      <td>14.551054</td>\n",
       "      <td>37.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600005</td>\n",
       "      <td>800005</td>\n",
       "      <td>600005</td>\n",
       "      <td>600005</td>\n",
       "      <td>2015-05-02</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>name1</td>\n",
       "      <td>13.006199</td>\n",
       "      <td>1</td>\n",
       "      <td>old</td>\n",
       "      <td>0.367381</td>\n",
       "      <td>49.406356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_LVL_ID6  LOCATION_LVL_ID8  CUSTOMER_LVL_ID6  DISTR_CHANNEL_LVL_ID6  \\\n",
       "0           600001            800001            600001                 600001   \n",
       "1           600002            800002            600002                 600002   \n",
       "2           600003            800003            600003                 600003   \n",
       "3           600004            800004            600004                 600004   \n",
       "4           600005            800005            600005                 600005   \n",
       "\n",
       "   PERIOD_DT PERIOD_END_DT SEGMENT_NAME  VF_FORECAST_VALUE  DEMAND_TYPE  \\\n",
       "0 2015-01-02    2015-02-01        name1           9.190933            0   \n",
       "1 2015-02-02    2015-03-01        name1          74.199686            1   \n",
       "2 2015-03-02    2015-04-01        name1          90.215905            1   \n",
       "3 2015-04-02    2015-05-01        name1           4.658254            0   \n",
       "4 2015-05-02    2015-06-01        name1          13.006199            1   \n",
       "\n",
       "  ASSORTMENT_TYPE  ML_FORECAST_VALUE  HYBRID_FORECAST_VALUE  \n",
       "0             old           2.833737              27.708736  \n",
       "1             new          44.958590              45.786556  \n",
       "2             new          40.587812              67.570161  \n",
       "3             old          14.551054              37.168200  \n",
       "4             old           0.367381              49.406356  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGG_HYB_FCST.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf65dd5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T12:15:41.171361Z",
     "start_time": "2022-07-17T12:15:41.147571Z"
    }
   },
   "outputs": [],
   "source": [
    "class Disaccumulation:\n",
    "    def __init__(self, data, out_time_lvl):\n",
    "        self.data = data.copy()\n",
    "        self.out_time_lvl = out_time_lvl\n",
    "        self.FINAL_GRANULARITY_DELIVERED = True\n",
    "        \n",
    "    def _get_period_start(self, dt, time_lvl):\n",
    "        if time_lvl == 'D':\n",
    "            return dt\n",
    "        elif time_lvl.startswith('W'):\n",
    "            if '.' in time_lvl:\n",
    "                parts = time_lvl.split('.')\n",
    "                if len(parts) > 1:\n",
    "                    day_num = int(parts[1])\n",
    "                    target_dow = (day_num - 2) % 7\n",
    "                else:\n",
    "                    target_dow = 6\n",
    "            else:\n",
    "                target_dow = 6\n",
    "            days_back = (dt.weekday() - target_dow) % 7\n",
    "            return dt - pd.Timedelta(days=days_back)\n",
    "        elif time_lvl == 'M':\n",
    "            return dt.replace(day=1)\n",
    "        return dt\n",
    "        \n",
    "    def _get_period_end(self, dt, time_lvl):\n",
    "        if time_lvl == 'D':\n",
    "            return dt\n",
    "        elif time_lvl.startswith('W'):\n",
    "            period_start = self._get_period_start(dt, time_lvl)\n",
    "            return period_start + pd.Timedelta(days=6)\n",
    "        elif time_lvl == 'M':\n",
    "            if dt.month == 12:\n",
    "                return dt.replace(year=dt.year + 1, month=1, day=1) - pd.Timedelta(days=1)\n",
    "            else:\n",
    "                return dt.replace(month=dt.month + 1, day=1) - pd.Timedelta(days=1)\n",
    "        return dt\n",
    "        \n",
    "    def check_granulatiry(self):\n",
    "        period_start_dt = self.data['PERIOD_DT'].apply(lambda x: self._get_period_start(x, self.out_time_lvl))\n",
    "        period_end_dt = self.data['PERIOD_END_DT'].apply(lambda x: self._get_period_start(x, self.out_time_lvl))\n",
    "        \n",
    "        if (period_start_dt != period_end_dt).any():\n",
    "            self.FINAL_GRANULARITY_DELIVERED = False\n",
    "            \n",
    "        return self.FINAL_GRANULARITY_DELIVERED\n",
    "        \n",
    "    def change_granularity(self):\n",
    "        result_rows = []\n",
    "        \n",
    "        for _, row in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
    "            period_dt = row['PERIOD_DT']\n",
    "            period_end_dt = row['PERIOD_END_DT']\n",
    "            \n",
    "            periods = []\n",
    "            current = period_dt\n",
    "            \n",
    "            while current <= period_end_dt:\n",
    "                period_start = self._get_period_start(current, self.out_time_lvl)\n",
    "                period_end = self._get_period_end(current, self.out_time_lvl)\n",
    "                \n",
    "                out_period_dt = max(period_dt, period_start)\n",
    "                out_period_end_dt = min(period_end_dt, period_end)\n",
    "                \n",
    "                if out_period_dt <= out_period_end_dt:\n",
    "                    periods.append((out_period_dt, out_period_end_dt))\n",
    "                \n",
    "                if period_end >= period_end_dt:\n",
    "                    break\n",
    "                    \n",
    "                current = period_end + pd.Timedelta(days=1)\n",
    "            \n",
    "            for out_pd, out_ped in periods:\n",
    "                new_row = row.copy()\n",
    "                new_row['OUT_PERIOD_DT'] = out_pd\n",
    "                new_row['OUT_PERIOD_END_DT'] = out_ped\n",
    "                result_rows.append(new_row)\n",
    "        \n",
    "        self.data_filled = pd.DataFrame(result_rows).reset_index(drop=True)\n",
    "        return self.data_filled\n",
    "    \n",
    "    def share_forecast(self):\n",
    "        def split_value(x, target_col):\n",
    "            orig_days = (x['PERIOD_END_DT'] - x['PERIOD_DT']).days + 1\n",
    "            out_days = (x['OUT_PERIOD_END_DT'] - x['OUT_PERIOD_DT']).days + 1\n",
    "            return x[target_col] * out_days / orig_days\n",
    "        \n",
    "        self.data_filled['VF_FORECAST_VALUE'] = self.data_filled.apply(lambda x: split_value(x, 'VF_FORECAST_VALUE'), axis=1)\n",
    "        self.data_filled['ML_FORECAST_VALUE'] = self.data_filled.apply(lambda x: split_value(x, 'ML_FORECAST_VALUE'), axis=1)\n",
    "        self.data_filled['HYBRID_FORECAST_VALUE'] = self.data_filled.apply(lambda x: split_value(x, 'HYBRID_FORECAST_VALUE'), axis=1)\n",
    "        \n",
    "        self.data_filled = self.data_filled.drop(['PERIOD_DT', 'PERIOD_END_DT'], axis=1)\n",
    "        self.data_filled = self.data_filled.rename(columns={'OUT_PERIOD_DT': 'PERIOD_DT', 'OUT_PERIOD_END_DT': 'PERIOD_END_DT'})\n",
    "        \n",
    "        id_cols = [col for col in self.data_filled.columns if '_ID' in col or col in ['SEGMENT_NAME', 'DEMAND_TYPE', 'ASSORTMENT_TYPE']]\n",
    "        sort_cols = id_cols + ['PERIOD_DT']\n",
    "        self.data_filled = self.data_filled.sort_values(sort_cols).reset_index(drop=True)\n",
    "        \n",
    "        return self.data_filled\n",
    "    \n",
    "    def provide_product_life_cycle(self, data):\n",
    "        return data\n",
    "    \n",
    "    def provide_location_life_cycle(self, data):\n",
    "        return data\n",
    "    \n",
    "    def provide_customer_life_cycle(self, data):\n",
    "        return data\n",
    "    \n",
    "    def split_forecasts(self):\n",
    "        self.check_granulatiry()\n",
    "        if not self.FINAL_GRANULARITY_DELIVERED:\n",
    "            self.change_granularity()\n",
    "            self.share_forecast()\n",
    "            result = self.data_filled\n",
    "        else:\n",
    "            result = self.data\n",
    "            \n",
    "        result = self.provide_product_life_cycle(result)\n",
    "        result = self.provide_location_life_cycle(result)\n",
    "        result = self.provide_customer_life_cycle(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e010c0bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T12:15:48.630645Z",
     "start_time": "2022-07-17T12:15:48.626547Z"
    }
   },
   "outputs": [],
   "source": [
    "Dis = Disaccumulation(AGG_HYB_FCST, 'W.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab59d0e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T12:16:39.502397Z",
     "start_time": "2022-07-17T12:15:49.047996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7e40a42d2047a9a881b816e410cc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ACC_AGG_HYBRID_FORECAST = Dis.split_forecasts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2342ebe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T12:16:39.520689Z",
     "start_time": "2022-07-17T12:16:39.504620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_LVL_ID6</th>\n",
       "      <th>LOCATION_LVL_ID8</th>\n",
       "      <th>CUSTOMER_LVL_ID6</th>\n",
       "      <th>DISTR_CHANNEL_LVL_ID6</th>\n",
       "      <th>SEGMENT_NAME</th>\n",
       "      <th>VF_FORECAST_VALUE</th>\n",
       "      <th>DEMAND_TYPE</th>\n",
       "      <th>ASSORTMENT_TYPE</th>\n",
       "      <th>ML_FORECAST_VALUE</th>\n",
       "      <th>HYBRID_FORECAST_VALUE</th>\n",
       "      <th>PERIOD_DT</th>\n",
       "      <th>PERIOD_END_DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600001</td>\n",
       "      <td>800001</td>\n",
       "      <td>600001</td>\n",
       "      <td>600001</td>\n",
       "      <td>name1</td>\n",
       "      <td>0.889445</td>\n",
       "      <td>0</td>\n",
       "      <td>old</td>\n",
       "      <td>0.274233</td>\n",
       "      <td>2.681491</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600001</td>\n",
       "      <td>800001</td>\n",
       "      <td>600001</td>\n",
       "      <td>600001</td>\n",
       "      <td>name1</td>\n",
       "      <td>2.075372</td>\n",
       "      <td>0</td>\n",
       "      <td>old</td>\n",
       "      <td>0.639876</td>\n",
       "      <td>6.256811</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600001</td>\n",
       "      <td>800001</td>\n",
       "      <td>600001</td>\n",
       "      <td>600001</td>\n",
       "      <td>name1</td>\n",
       "      <td>2.075372</td>\n",
       "      <td>0</td>\n",
       "      <td>old</td>\n",
       "      <td>0.639876</td>\n",
       "      <td>6.256811</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>2015-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600001</td>\n",
       "      <td>800001</td>\n",
       "      <td>600001</td>\n",
       "      <td>600001</td>\n",
       "      <td>name1</td>\n",
       "      <td>2.075372</td>\n",
       "      <td>0</td>\n",
       "      <td>old</td>\n",
       "      <td>0.639876</td>\n",
       "      <td>6.256811</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>2015-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600001</td>\n",
       "      <td>800001</td>\n",
       "      <td>600001</td>\n",
       "      <td>600001</td>\n",
       "      <td>name1</td>\n",
       "      <td>2.075372</td>\n",
       "      <td>0</td>\n",
       "      <td>old</td>\n",
       "      <td>0.639876</td>\n",
       "      <td>6.256811</td>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>2015-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_LVL_ID6  LOCATION_LVL_ID8  CUSTOMER_LVL_ID6  DISTR_CHANNEL_LVL_ID6  \\\n",
       "0           600001            800001            600001                 600001   \n",
       "1           600001            800001            600001                 600001   \n",
       "2           600001            800001            600001                 600001   \n",
       "3           600001            800001            600001                 600001   \n",
       "4           600001            800001            600001                 600001   \n",
       "\n",
       "  SEGMENT_NAME  VF_FORECAST_VALUE  DEMAND_TYPE ASSORTMENT_TYPE  \\\n",
       "0        name1           0.889445            0             old   \n",
       "1        name1           2.075372            0             old   \n",
       "2        name1           2.075372            0             old   \n",
       "3        name1           2.075372            0             old   \n",
       "4        name1           2.075372            0             old   \n",
       "\n",
       "   ML_FORECAST_VALUE  HYBRID_FORECAST_VALUE  PERIOD_DT PERIOD_END_DT  \n",
       "0           0.274233               2.681491 2015-01-02    2015-01-04  \n",
       "1           0.639876               6.256811 2015-01-05    2015-01-11  \n",
       "2           0.639876               6.256811 2015-01-12    2015-01-18  \n",
       "3           0.639876               6.256811 2015-01-19    2015-01-25  \n",
       "4           0.639876               6.256811 2015-01-26    2015-02-01  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACC_AGG_HYBRID_FORECAST.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dbac526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-17T12:16:39.537994Z",
     "start_time": "2022-07-17T12:16:39.522672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10409, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACC_AGG_HYBRID_FORECAST.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aff939",
   "metadata": {},
   "source": [
    "### Disaccumaltion testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af907d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_disaccumulation():    \n",
    "    print(\"\\n1. Creating test data\")\n",
    "    test_data = pd.DataFrame({\n",
    "        'PRODUCT_LVL_ID6': [600001, 600002, 600003],\n",
    "        'LOCATION_LVL_ID8': [800001, 800002, 800003],\n",
    "        'CUSTOMER_LVL_ID6': [600001, 600002, 600003],\n",
    "        'DISTR_CHANNEL_LVL_ID6': [600001, 600002, 600003],\n",
    "        'PERIOD_DT': pd.to_datetime(['2015-01-02', '2015-02-02', '2015-03-02']),\n",
    "        'PERIOD_END_DT': pd.to_datetime(['2015-02-01', '2015-03-01', '2015-04-01']),\n",
    "        'SEGMENT_NAME': ['seg1', 'seg2', 'seg3'],\n",
    "        'VF_FORECAST_VALUE': [100.0, 200.0, 300.0],\n",
    "        'DEMAND_TYPE': [0, 1, 0],\n",
    "        'ASSORTMENT_TYPE': ['new', 'old', 'new'],\n",
    "        'ML_FORECAST_VALUE': [50.0, 150.0, 250.0],\n",
    "        'HYBRID_FORECAST_VALUE': [75.0, 175.0, 275.0]\n",
    "    })\n",
    "    print(f\"   Created {len(test_data)} test rows\")\n",
    "    \n",
    "    print(\"\\n2. Testing granularity check\")\n",
    "    dis = Disaccumulation(test_data, 'W.2')\n",
    "    is_final = dis.check_granulatiry()\n",
    "    assert not is_final, \"Should detect that monthly periods need splitting\"\n",
    "    print(\"   Granularity check works (detected need for splitting)\")\n",
    "    \n",
    "    print(\"\\n3. Testing period splitting (monthly -> weekly)\")\n",
    "    result = dis.split_forecasts()\n",
    "    print(f\"   Split {len(test_data)} rows into {len(result)} rows\")\n",
    "    \n",
    "    assert len(result) > len(test_data), \"Should have more rows after splitting\"\n",
    "    print(\"   Period splitting successful\")\n",
    "    \n",
    "    print(\"\\n4. Validating results\")\n",
    "    \n",
    "    required_cols = ['PRODUCT_LVL_ID6', 'LOCATION_LVL_ID8', 'CUSTOMER_LVL_ID6', \n",
    "                     'DISTR_CHANNEL_LVL_ID6', 'PERIOD_DT', 'PERIOD_END_DT',\n",
    "                     'VF_FORECAST_VALUE', 'ML_FORECAST_VALUE', 'HYBRID_FORECAST_VALUE',\n",
    "                     'SEGMENT_NAME', 'DEMAND_TYPE', 'ASSORTMENT_TYPE']\n",
    "    missing_cols = [col for col in required_cols if col not in result.columns]\n",
    "    assert len(missing_cols) == 0, f\"Missing columns: {missing_cols}\"\n",
    "    print(\"   All required columns present\")\n",
    "    \n",
    "    assert result['PERIOD_DT'].dtype == 'datetime64[ns]', \"PERIOD_DT should be datetime\"\n",
    "    assert result['PERIOD_END_DT'].dtype == 'datetime64[ns]', \"PERIOD_END_DT should be datetime\"\n",
    "    print(\"   Date columns are datetime type\")\n",
    "    \n",
    "    assert (result['PERIOD_DT'] <= result['PERIOD_END_DT']).all(), \"PERIOD_DT should be <= PERIOD_END_DT\"\n",
    "    print(\"   Date ranges are valid\")\n",
    "    \n",
    "    print(\"\\n5. Testing forecast value distribution\")\n",
    "    for idx in test_data.index:\n",
    "        orig_row = test_data.iloc[idx]\n",
    "        split_rows = result[\n",
    "            (result['PRODUCT_LVL_ID6'] == orig_row['PRODUCT_LVL_ID6']) &\n",
    "            (result['LOCATION_LVL_ID8'] == orig_row['LOCATION_LVL_ID8']) &\n",
    "            (result['CUSTOMER_LVL_ID6'] == orig_row['CUSTOMER_LVL_ID6']) &\n",
    "            (result['DISTR_CHANNEL_LVL_ID6'] == orig_row['DISTR_CHANNEL_LVL_ID6'])\n",
    "        ]\n",
    "        \n",
    "        orig_days = (orig_row['PERIOD_END_DT'] - orig_row['PERIOD_DT']).days + 1\n",
    "        total_vf = split_rows['VF_FORECAST_VALUE'].sum()\n",
    "        total_ml = split_rows['ML_FORECAST_VALUE'].sum()\n",
    "        total_hybrid = split_rows['HYBRID_FORECAST_VALUE'].sum()\n",
    "        \n",
    "        assert np.isclose(total_vf, orig_row['VF_FORECAST_VALUE'], rtol=1e-5), \\\n",
    "            f\"VF_FORECAST_VALUE not preserved: {total_vf} vs {orig_row['VF_FORECAST_VALUE']}\"\n",
    "        assert np.isclose(total_ml, orig_row['ML_FORECAST_VALUE'], rtol=1e-5), \\\n",
    "            f\"ML_FORECAST_VALUE not preserved: {total_ml} vs {orig_row['ML_FORECAST_VALUE']}\"\n",
    "        assert np.isclose(total_hybrid, orig_row['HYBRID_FORECAST_VALUE'], rtol=1e-5), \\\n",
    "            f\"HYBRID_FORECAST_VALUE not preserved: {total_hybrid} vs {orig_row['HYBRID_FORECAST_VALUE']}\"\n",
    "    \n",
    "    print(\"   Forecast values correctly distributed (sums match original)\")\n",
    "    \n",
    "    print(\"\\n6. Testing already-correct granularity\")\n",
    "    daily_data = pd.DataFrame({\n",
    "        'PRODUCT_LVL_ID6': [600001],\n",
    "        'LOCATION_LVL_ID8': [800001],\n",
    "        'CUSTOMER_LVL_ID6': [600001],\n",
    "        'DISTR_CHANNEL_LVL_ID6': [600001],\n",
    "        'PERIOD_DT': pd.to_datetime(['2015-01-05']),\n",
    "        'PERIOD_END_DT': pd.to_datetime(['2015-01-05']),\n",
    "        'SEGMENT_NAME': ['seg1'],\n",
    "        'VF_FORECAST_VALUE': [100.0],\n",
    "        'DEMAND_TYPE': [0],\n",
    "        'ASSORTMENT_TYPE': ['new'],\n",
    "        'ML_FORECAST_VALUE': [50.0],\n",
    "        'HYBRID_FORECAST_VALUE': [75.0]\n",
    "    })\n",
    "    \n",
    "    dis_daily = Disaccumulation(daily_data, 'D')\n",
    "    is_final_daily = dis_daily.check_granulatiry()\n",
    "    assert is_final_daily, \"Daily data with daily granularity should be final\"\n",
    "    result_daily = dis_daily.split_forecasts()\n",
    "    assert len(result_daily) == len(daily_data), \"Should not split when already correct\"\n",
    "    print(\"   Handles already-correct granularity\")\n",
    "    \n",
    "    print(\"\\n7. Testing week calculation\")\n",
    "    test_date = pd.to_datetime('2015-01-07')\n",
    "    week_start = dis._get_period_start(test_date, 'W.2')\n",
    "    assert week_start.weekday() == 0, \"W.2 should start on Monday\"\n",
    "    print(\"   Week calculation correct (W.2 = Monday start)\")\n",
    "    \n",
    "    print(\"\\n8. Results summary:\")\n",
    "    print(f\"   Original rows: {len(test_data)}\")\n",
    "    print(f\"   Result rows: {len(result)}\")\n",
    "    print(f\"   Expansion factor: {len(result) / len(test_data):.2f}x\")\n",
    "    print(f\"   Date range: {result['PERIOD_DT'].min()} to {result['PERIOD_END_DT'].max()}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-/\" * 35)\n",
    "    print(\"ALL TESTS PASSED!\")\n",
    "    print(\"-/\" * 35)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5668675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Creating test data\n",
      "   Created 3 test rows\n",
      "\n",
      "2. Testing granularity check\n",
      "   Granularity check works (detected need for splitting)\n",
      "\n",
      "3. Testing period splitting (monthly -> weekly)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfee0b5ac68a418c903cabd7f507bea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Split 3 rows into 14 rows\n",
      "   Period splitting successful\n",
      "\n",
      "4. Validating results\n",
      "   All required columns present\n",
      "   Date columns are datetime type\n",
      "   Date ranges are valid\n",
      "\n",
      "5. Testing forecast value distribution\n",
      "   Forecast values correctly distributed (sums match original)\n",
      "\n",
      "6. Testing already-correct granularity\n",
      "   Handles already-correct granularity\n",
      "\n",
      "7. Testing week calculation\n",
      "   Week calculation correct (W.2 = Monday start)\n",
      "\n",
      "8. Results summary:\n",
      "   Original rows: 3\n",
      "   Result rows: 14\n",
      "   Expansion factor: 4.67x\n",
      "   Date range: 2015-01-02 00:00:00 to 2015-04-01 00:00:00\n",
      "\n",
      "-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/\n",
      "ALL TESTS PASSED!\n",
      "-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/\n"
     ]
    }
   ],
   "source": [
    "result = test_disaccumulation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
